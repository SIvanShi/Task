{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e71188f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "------------------------------\n",
      "load train images...\n",
      "------------------------------\n",
      "------------------------------\n",
      "load test images...\n",
      "------------------------------\n",
      "loading data done\n",
      "conv1 shape: (None, 512, 512, 64)\n",
      "conv1 shape: (None, 512, 512, 64)\n",
      "pool1 shape: (None, 256, 256, 64)\n",
      "conv2 shape: (None, 256, 256, 128)\n",
      "conv2 shape: (None, 256, 256, 128)\n",
      "pool2 shape: (None, 128, 128, 128)\n",
      "conv3 shape: (None, 128, 128, 256)\n",
      "conv3 shape: (None, 128, 128, 256)\n",
      "pool3 shape: (None, 64, 64, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-03 20:54:19.043288: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-03 20:54:19.043762: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv10 shape: (None, 512, 512, 64)\n",
      "conv10 shape: (None, 512, 512, 64)\n",
      "pool10 shape: (None, 256, 256, 64)\n",
      "conv11 shape: (None, 256, 256, 128)\n",
      "conv11 shape: (None, 256, 256, 128)\n",
      "pool11 shape: (None, 128, 128, 128)\n",
      "conv12 shape: (None, 128, 128, 256)\n",
      "conv12 shape: (None, 128, 128, 256)\n",
      "pool12 shape: (None, 64, 64, 256)\n",
      "got unet\n",
      "Fitting model...\n",
      "Train on 16 samples, validate on 5 samples\n",
      "Epoch 1/20\n",
      "16/16 [==============================] - 205s 13s/step - loss: 0.6930 - accuracy: 0.9835 - val_loss: 0.6928 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.69298, saving model to my_unet.hdf5\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shiyufan/opt/anaconda3/lib/python3.7/site-packages/keras/engine/saving.py:165: UserWarning: TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
      "  'TensorFlow optimizers do not '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 205s 13s/step - loss: 0.6411 - accuracy: 0.9837 - val_loss: 0.3470 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00002: loss improved from 0.69298 to 0.64106, saving model to my_unet.hdf5\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 205s 13s/step - loss: 0.2884 - accuracy: 0.9837 - val_loss: 0.3042 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00003: loss improved from 0.64106 to 0.28838, saving model to my_unet.hdf5\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 203s 13s/step - loss: 0.1937 - accuracy: 0.9837 - val_loss: 0.2420 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00004: loss improved from 0.28838 to 0.19368, saving model to my_unet.hdf5\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 203s 13s/step - loss: 0.1249 - accuracy: 0.9837 - val_loss: 0.1116 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00005: loss improved from 0.19368 to 0.12486, saving model to my_unet.hdf5\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 204s 13s/step - loss: 0.0667 - accuracy: 0.9837 - val_loss: 0.0742 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00006: loss improved from 0.12486 to 0.06670, saving model to my_unet.hdf5\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 207s 13s/step - loss: 0.0545 - accuracy: 0.9837 - val_loss: 0.0995 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00007: loss improved from 0.06670 to 0.05452, saving model to my_unet.hdf5\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 212s 13s/step - loss: 0.0494 - accuracy: 0.9837 - val_loss: 0.0708 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00008: loss improved from 0.05452 to 0.04937, saving model to my_unet.hdf5\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 204s 13s/step - loss: 0.0461 - accuracy: 0.9837 - val_loss: 0.0665 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00009: loss improved from 0.04937 to 0.04614, saving model to my_unet.hdf5\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 203s 13s/step - loss: 0.0437 - accuracy: 0.9837 - val_loss: 0.0611 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00010: loss improved from 0.04614 to 0.04371, saving model to my_unet.hdf5\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 203s 13s/step - loss: 0.0409 - accuracy: 0.9837 - val_loss: 0.0593 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00011: loss improved from 0.04371 to 0.04092, saving model to my_unet.hdf5\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 204s 13s/step - loss: 0.0386 - accuracy: 0.9837 - val_loss: 0.0623 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00012: loss improved from 0.04092 to 0.03858, saving model to my_unet.hdf5\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 204s 13s/step - loss: 0.0358 - accuracy: 0.9837 - val_loss: 0.0519 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00013: loss improved from 0.03858 to 0.03581, saving model to my_unet.hdf5\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 202s 13s/step - loss: 0.0331 - accuracy: 0.9837 - val_loss: 0.0525 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00014: loss improved from 0.03581 to 0.03309, saving model to my_unet.hdf5\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 203s 13s/step - loss: 0.0316 - accuracy: 0.9837 - val_loss: 0.0536 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00015: loss improved from 0.03309 to 0.03164, saving model to my_unet.hdf5\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 203s 13s/step - loss: 0.0293 - accuracy: 0.9837 - val_loss: 0.0513 - val_accuracy: 0.9836\n",
      "\n",
      "Epoch 00016: loss improved from 0.03164 to 0.02932, saving model to my_unet.hdf5\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 202s 13s/step - loss: 0.0274 - accuracy: 0.9837 - val_loss: 0.0536 - val_accuracy: 0.9835\n",
      "\n",
      "Epoch 00017: loss improved from 0.02932 to 0.02742, saving model to my_unet.hdf5\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 204s 13s/step - loss: 0.0292 - accuracy: 0.9838 - val_loss: 0.0493 - val_accuracy: 0.9827\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.02742\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 203s 13s/step - loss: 0.0294 - accuracy: 0.9846 - val_loss: 0.0518 - val_accuracy: 0.9818\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.02742\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 203s 13s/step - loss: 0.0251 - accuracy: 0.9867 - val_loss: 0.0408 - val_accuracy: 0.9787\n",
      "\n",
      "Epoch 00020: loss improved from 0.02742 to 0.02514, saving model to my_unet.hdf5\n",
      "predict test data\n",
      "21/21 [==============================] - 92s 4s/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Concatenate\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from data import *\n",
    "\n",
    "\n",
    "class myUnet(object):\n",
    "\tdef __init__(self, img_rows = 512, img_cols = 512):\n",
    "\t\tself.img_rows = img_rows\n",
    "\t\tself.img_cols = img_cols\n",
    "# parameter initialization definition\n",
    "\tdef load_data(self):\n",
    "\t\tmydata = dataProcess(self.img_rows, self.img_cols)\n",
    "\t\timgs_train, imgs_mask_train = mydata.load_train_data()\n",
    "\t\timgs_test = mydata.load_test_data()\n",
    "\t\treturn imgs_train, imgs_mask_train, imgs_test\n",
    "# load dataset to network\n",
    "\tdef get_unet(self):\n",
    "\t\tinputs = Input((self.img_rows, self.img_cols,1))\n",
    "\n",
    "\t\tconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "\t\tprint (\"conv1 shape:\",conv1.shape)\n",
    "\t\tconv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "\t\tprint (\"conv1 shape:\",conv1.shape)\n",
    "\t\tpool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\t\tprint (\"pool1 shape:\",pool1.shape)\n",
    "\n",
    "\t\tconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "\t\tprint (\"conv2 shape:\",conv2.shape)\n",
    "\t\tconv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "\t\tprint (\"conv2 shape:\",conv2.shape)\n",
    "\t\tpool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\t\tprint (\"pool2 shape:\",pool2.shape)\n",
    "\n",
    "\t\tconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "\t\tprint (\"conv3 shape:\",conv3.shape)\n",
    "\t\tconv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "\t\tprint (\"conv3 shape:\",conv3.shape)\n",
    "\t\tpool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\t\tprint (\"pool3 shape:\",pool3.shape)\n",
    "\n",
    "\t\tconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "\t\tconv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "\t\tdrop4 = Dropout(0.5)(conv4)\n",
    "\t\tpool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "\t\tconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "\t\tconv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "\t\tdrop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "\t\tup6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "\t\tmerge6 = Concatenate(axis=3)([drop4, up6])\n",
    "\t\tconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "\t\tconv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "\t\tup7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "\t\tmerge7 = Concatenate(axis=3)([conv3, up7])\n",
    "\t\tconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "\t\tconv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "\t\tup8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "\t\tmerge8 = Concatenate(axis=3)([conv2,up8])\n",
    "\t\tconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "\t\tconv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "\t\tup9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "\t\tmerge9 = Concatenate(axis=3)([conv1,up9])\n",
    "\t\tconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "\t\tconv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "\t\tconv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "\t\tconv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "\t\tconv10 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "\t\tprint(\"conv10 shape:\", conv10.shape)\n",
    "\t\tconv10 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv10)\n",
    "\t\tprint(\"conv10 shape:\", conv10.shape)\n",
    "\t\tpool10 = MaxPooling2D(pool_size=(2, 2))(conv10)\n",
    "\t\tprint(\"pool10 shape:\", pool10.shape)\n",
    "\n",
    "\t\tconv11 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool10)\n",
    "\t\tprint(\"conv11 shape:\", conv11.shape)\n",
    "\t\tconv11 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv11)\n",
    "\t\tprint(\"conv11 shape:\", conv11.shape)\n",
    "\t\tpool11 = MaxPooling2D(pool_size=(2, 2))(conv11)\n",
    "\t\tprint(\"pool11 shape:\", pool11.shape)\n",
    "\n",
    "\t\tconv12 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool11)\n",
    "\t\tprint(\"conv12 shape:\", conv12.shape)\n",
    "\t\tconv12 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv12)\n",
    "\t\tprint(\"conv12 shape:\", conv12.shape)\n",
    "\t\tpool12 = MaxPooling2D(pool_size=(2, 2))(conv12)\n",
    "\t\tprint(\"pool12 shape:\", pool12.shape)\n",
    "\n",
    "\t\tconv13 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool12)\n",
    "\t\tconv13 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv13)\n",
    "\t\tdrop13 = Dropout(0.5)(conv13)\n",
    "\t\tpool13 = MaxPooling2D(pool_size=(2, 2))(drop13)\n",
    "\n",
    "\t\tconv14 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool13)\n",
    "\t\tconv14 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv14)\n",
    "\t\tdrop14 = Dropout(0.5)(conv14)\n",
    "\n",
    "\t\tup15 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "\t\t\tUpSampling2D(size=(2, 2))(drop14))\n",
    "\t\tmerge15 = Concatenate(axis=3)([drop13, up15])\n",
    "\t\tconv15 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge15)\n",
    "\t\tconv15 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv15)\n",
    "\n",
    "\t\tup16 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "\t\t\tUpSampling2D(size=(2, 2))(conv15))\n",
    "\t\tmerge16 = Concatenate(axis=3)([conv12, up16])\n",
    "\t\tconv16 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge16)\n",
    "\t\tconv16 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv16)\n",
    "\n",
    "\t\tup17 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "\t\t\tUpSampling2D(size=(2, 2))(conv16))\n",
    "\t\tmerge17 = Concatenate(axis=3)([conv11, up17])\n",
    "\t\tconv17 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge17)\n",
    "\t\tconv17 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv17)\n",
    "\n",
    "\t\tup18 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(\n",
    "\t\t\tUpSampling2D(size=(2, 2))(conv17))\n",
    "\t\tmerge18 = Concatenate(axis=3)([conv10, up18])\n",
    "\t\tconv18 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge18)\n",
    "\t\tconv18 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv18)\n",
    "\t\tconv18 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv18)\n",
    "\t\tconv19 = Conv2D(1, 1, activation='sigmoid')(conv18)\n",
    "\n",
    "\t\tmodel = Model(inputs, conv19)\n",
    "\t\tmodel.compile(optimizer = tf.keras.optimizers.Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\t\treturn model\n",
    "\n",
    "\n",
    "\tdef train(self):\n",
    "\t\tprint(\"loading data\")\n",
    "\t\timgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
    "\t\tprint(\"loading data done\")\n",
    "\t\tmodel = self.get_unet()\n",
    "\t\tprint(\"got unet\")\n",
    "\t\tmodel_checkpoint = ModelCheckpoint('my_unet.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "\t\tprint('Fitting model...')\n",
    "\t\tmodel.fit(imgs_train, imgs_mask_train, batch_size=2, epochs=20, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "\n",
    "\t\tprint('predict test data')\n",
    "\t\timgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n",
    "\t\tnp.save('./results/imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "\tdef save_img(self):\n",
    "\t\tprint(\"array to image\")\n",
    "\t\timgs = np.load('./results/imgs_mask_test.npy')\n",
    "\t\timgs_name = sorted(glob.glob(\"./raw/test\"+\"/*.\"+\"tif\"))\n",
    "\t\tfor i in range(imgs.shape[0]):\n",
    "\t\t\timg = imgs[i]\n",
    "\t\t\timgname = imgs_name[i]\n",
    "\t\t\tmidname = imgname[imgname.rindex(\"/\") + 1:]\n",
    "\t\t\timg_order = midname[:-4]\n",
    "\t\t\timg = array_to_img(img)\n",
    "\t\t\timg.save(\"./results/%s.jpg\"%(img_order))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmyunet = myUnet()\n",
    "\tmyunet.train()\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93642c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'SimpleITK'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/2t/2fy1f60s7dj_wgg2bf0_fjrc0000gn/T/ipykernel_26070/1861038131.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleITK\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msitk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#load tested image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'SimpleITK'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "\n",
    "#load tested image\n",
    "dcm_file = './raw/test/'\n",
    "dcm_seg = './results/'\n",
    "\n",
    "\n",
    "#draw contour\n",
    "def drawContour():\n",
    "\n",
    "    image = sitk.ReadImage(dcm_file)\n",
    "    image_array = sitk.GetArrayFromImage(image)\n",
    "    image_array = np.squeeze(image_array)\n",
    "    image_array = image_array.astype(np.float32)\n",
    "\n",
    "    image_array = (image_array - (-200)) / 400.0\n",
    "    image_array[image_array > 1] = 1.0\n",
    "    image_array[image_array < 0] = 0.0\n",
    "\n",
    "    # If it is not converted to color, then the contour drawn at the end can only be grayscale\n",
    "    image_array = cv2.cvtColor(image_array, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    seg = sitk.ReadImage(dcm_seg)\n",
    "    seg_array = sitk.GetArrayFromImage(seg)\n",
    "    seg_array = np.squeeze(seg_array)\n",
    "\n",
    "    # findContours must target white and background black (0,1 and 0,255 are fine)\n",
    "    contours, hierarchy = cv2.findContours(seg_array, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "\n",
    "    cnt = contours[0]\n",
    "    # drawContours directly changes the original image\n",
    "    # Third parameter index\n",
    "    # The fourth parameter color: BGR\n",
    "    # Two different ways to specify which contour to draw\n",
    "    cv2.drawContours(image_array, [cnt], 0, (0, 255, 0), 1)\n",
    "    cv2.drawContours(image_array, contours, -1, (0, 255, 0), 1) # index=-1 means to draw all contours\n",
    "    cv2.imwrite(\"./track/\"+\"19.tif\", image_array)\n",
    "\n",
    "\n",
    "drawContour()\n",
    "\n",
    "#image to video\n",
    "import cv2\n",
    "img_root = './track/'\n",
    "fps = 5\n",
    "size=(512,512)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'X264')\n",
    "videoWriter = cv2.VideoWriter('./track/track_results.mp4',fourcc,fps,size)\n",
    "for i in range(1,20):\n",
    "    frame = cv2.imread(img_root+str(i)+'.tif')\n",
    "    videoWriter.write(frame)\n",
    "videoWriter.release()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce90e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
